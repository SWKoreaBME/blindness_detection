{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "tensor(1.3262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6398, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.2623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(2.0112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(2.0584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.2245, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(2.0218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7393, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9115, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6236, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8305, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9432, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5483, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7558, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(2.1109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7100, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.2540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.1288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.2728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.2303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9426, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6448, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(2.0153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5253, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4182, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.2581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(2.0066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3729, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6278, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.1670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(2.0544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.2215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8198, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(2.0060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3405, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.2612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6510, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.2766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3204, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5860, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.2431, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.1844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(2.1982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6548, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5489, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5322, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7200, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5067, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6464, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.2620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(2.0047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(2.1756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6194, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.2462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3201, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4817, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.2620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9485, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5559, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7315, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(2.1346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(2.1316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(2.0371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5282, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5000, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6265, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6238, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4209, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(2.0534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.9895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.2957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5556, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(2.2195, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.7994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3031, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.5993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.6960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.8401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.3738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "tensor(1.4748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-fd1a3f9db240>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mX_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/바탕화면/projects/blindness_detection/base_classification/aptos_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mimg_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/바탕화면/projects/blindness_detection/base_classification/aptos_dataset.py\u001b[0m in \u001b[0;36mread_image\u001b[0;34m(self, image_name)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import utils\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch\n",
    "\n",
    "from aptos_dataset import aptos_dataset\n",
    "from preprocessing import preprocessing\n",
    "from model import classifier\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "data_dir = '/media/sangwook/MGTEC/blindness_detection_data/2019/train_images/'\n",
    "label_file = '/media/sangwook/MGTEC/blindness_detection_data/2019/train_2019.csv'\n",
    "\n",
    "dataset = aptos_dataset(d_path=data_dir, label_file=label_file)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, amsgrad=False)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "num_classes = 5\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(in_features=51200, out_features=num_classes, bias=False)\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    exp_lr_scheduler.step()\n",
    "\n",
    "    for i_batch, sample_batch in enumerate(dataloader):\n",
    "\n",
    "        X_ = sample_batch['image'].to(device).float()\n",
    "        y_true = sample_batch['label'].to(device)\n",
    "\n",
    "        # TODO: import Classifier\n",
    "\n",
    "        y_output = model(X_)\n",
    "        _, preds = torch.max(y_output, 1)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_ = loss_function(y_output, y_true)\n",
    "        loss_.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(loss_)\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 2, 4], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2431, -0.1761,  0.9961, -0.3093,  0.7021],\n",
       "         [ 0.5917,  0.5105,  1.2794, -0.6101,  0.3022],\n",
       "         [-0.0390, -0.9371,  1.1241,  0.2495,  1.1459],\n",
       "         [-0.7444,  0.0964,  0.4105, -0.2357,  0.2959]], device='cuda:0',\n",
       "        grad_fn=<MmBackward>), tensor([0, 2, 2, 4], device='cuda:0'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_output.float(), y_true.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
